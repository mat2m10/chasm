{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44b427e-a340-44e9-b82f-ecbde67ff903",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb744cb-08bc-4eeb-ab37-73fb5633c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2726b3-f82c-4aad-abfb-695db6bc177c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:20:48.266790Z",
     "iopub.status.busy": "2025-09-09T08:20:48.265974Z",
     "iopub.status.idle": "2025-09-09T08:20:48.271990Z",
     "shell.execute_reply": "2025-09-09T08:20:48.271334Z",
     "shell.execute_reply.started": "2025-09-09T08:20:48.266772Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_AFs(path_data, name_file_input, path_plink, path_output, threads=4):\n",
    "    Path(path_output).mkdir(parents=True, exist_ok=True)\n",
    "    for chrom in range(1, 23):\n",
    "        name_file_output = f\"chrom_{chrom}_AFs_{name_file_input}\"\n",
    "        cmd = [\n",
    "            f\"{Path(path_plink) / 'plink2'}\",\n",
    "            \"--bfile\", name_file_input,\n",
    "            \"--chr\", str(chrom),\n",
    "            \"--freq\",\n",
    "            \"--threads\", str(threads),\n",
    "            \"--out\", str(Path(path_output) / name_file_output),\n",
    "        ]\n",
    "        # run inside path_data so relative --bfile works\n",
    "        subprocess.run(cmd, cwd=path_data, check=True, capture_output=True, text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97074e6f-70f8-4535-ba42-60d0d17b2870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:26:40.601427Z",
     "iopub.status.busy": "2025-09-09T08:26:40.601142Z",
     "iopub.status.idle": "2025-09-09T08:26:40.607099Z",
     "shell.execute_reply": "2025-09-09T08:26:40.606612Z",
     "shell.execute_reply.started": "2025-09-09T08:26:40.601408Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def concat_AFs(path_input, path_output):\n",
    "    Path(path_output).mkdir(parents=True, exist_ok=True)\n",
    "    af_files = [f for f in os.listdir(path_input) if f.endswith(\".afreq\")]\n",
    "    chroms = sorted({f.split('_')[1] for f in af_files})  # 'chrom_1', etc.\n",
    "    pops = sorted({f.split(\"_AFs_\")[1].split(\".\")[0] for f in af_files})\n",
    "\n",
    "    for chrom in chroms:\n",
    "        dfs = []\n",
    "        for pop in pops:\n",
    "            p = Path(path_input) / f\"chrom_{chrom}_AFs_{pop}.afreq\"\n",
    "            df = pd.read_csv(p, sep=r\"\\s+\")\n",
    "            # ALT_FREQS is AF for ALT; fold to MAF only at the end after weighting\n",
    "            df = df.rename(columns={\"ALT_FREQS\": f\"ALT_FREQS_{pop}\", \"OBS_CT\": f\"OBS_CT_{pop}\"})\n",
    "            dfs.append(df)\n",
    "\n",
    "        base = dfs[0]\n",
    "        for d in dfs[1:]:\n",
    "            base = base.merge(d, on=[\"#CHROM\",\"ID\",\"REF\",\"ALT\",\"PROVISIONAL_REF?\"], how=\"inner\")\n",
    "\n",
    "        # Weighted global ALT freq across populations\n",
    "        total_alt = 0.0\n",
    "        total_obs = 0.0\n",
    "        for pop in pops:\n",
    "            base[f\"ALT_COUNT_{pop}\"] = base[f\"ALT_FREQS_{pop}\"] * base[f\"OBS_CT_{pop}\"]\n",
    "            total_alt += base[f\"ALT_COUNT_{pop}\"]\n",
    "            total_obs += base[f\"OBS_CT_{pop}\"]\n",
    "        base[\"TOTAL_ALT_FREQ\"] = (total_alt / total_obs).astype(\"float32\")\n",
    "\n",
    "        # Convert to **MAF** in [0, 0.5]\n",
    "        base[\"TOTAL_MAF\"] = np.minimum(base[\"TOTAL_ALT_FREQ\"], 1.0 - base[\"TOTAL_ALT_FREQ\"]).astype(\"float32\")\n",
    "\n",
    "        base.to_pickle(Path(path_output) / f\"global_AF_{chrom}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ea6fc53-5bc1-4f47-a1d8-fb8de25181f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:34:43.312380Z",
     "iopub.status.busy": "2025-09-09T08:34:43.312208Z",
     "iopub.status.idle": "2025-09-09T08:34:43.323262Z",
     "shell.execute_reply": "2025-09-09T08:34:43.322783Z",
     "shell.execute_reply.started": "2025-09-09T08:34:43.312369Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil, subprocess, tempfile\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "PRIORITY = [\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\",\"PHENOTYPE\"]\n",
    "\n",
    "def _resolve_plink2(path_plink: str) -> str:\n",
    "    p = Path(path_plink)\n",
    "    if p.is_file() and os.access(p, os.X_OK):\n",
    "        return str(p)\n",
    "    cand = p / \"plink2\"\n",
    "    if cand.is_file() and os.access(cand, os.X_OK):\n",
    "        return str(cand)\n",
    "    which = shutil.which(\"plink2\")\n",
    "    if which: return which\n",
    "    raise FileNotFoundError(f\"plink2 not found at '{path_plink}' and not in PATH\")\n",
    "\n",
    "def _find_bfiles(path_dir: str):\n",
    "    d = Path(path_dir)\n",
    "    fams = {p.stem for p in d.glob(\"*.fam\")}\n",
    "    trios = [pref for pref in sorted(fams)\n",
    "             if (d/f\"{pref}.bed\").exists() and (d/f\"{pref}.bim\").exists()]\n",
    "    return trios\n",
    "\n",
    "def divide_into_chunks(path_input_afs,\n",
    "                       path_input_plink_bfiles,\n",
    "                       path_plink,\n",
    "                       path_output,\n",
    "                       size_chunk=20_000,\n",
    "                       min_maf=0.01,\n",
    "                       threads=4,\n",
    "                       chroms=None,\n",
    "                       bfiles=None,      # <— NEW: explicitly choose, e.g. [\"1000g\"]\n",
    "                       verbose=True):\n",
    "    plink2_bin = _resolve_plink2(path_plink)\n",
    "    out_root = Path(path_output); out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    auto_bfiles = _find_bfiles(path_input_plink_bfiles)\n",
    "    if bfiles is None:\n",
    "        bfiles = auto_bfiles\n",
    "    else:\n",
    "        # keep only those that truly have .bed/.bim/.fam\n",
    "        bfiles = [b for b in bfiles if b in auto_bfiles]\n",
    "\n",
    "    if not bfiles:\n",
    "        raise RuntimeError(f\"No valid PLINK bfiles found. Present trios: {auto_bfiles}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[divide_into_chunks] Using plink2: {plink2_bin}\")\n",
    "        print(f\"[divide_into_chunks] Bfiles: {bfiles}\")\n",
    "\n",
    "    af_pkls_all = sorted(Path(path_input_afs).glob(\"global_AF_*.pkl\"))\n",
    "    if not af_pkls_all:\n",
    "        raise RuntimeError(f\"No AF files in {path_input_afs} (expected global_AF_chrom_*.pkl)\")\n",
    "\n",
    "    def _chr(p): return p.stem.split(\"_\")[-1]\n",
    "    if chroms is not None:\n",
    "        keep = {str(c) for c in chroms}\n",
    "        af_pkls = [p for p in af_pkls_all if _chr(p) in keep]\n",
    "    else:\n",
    "        af_pkls = af_pkls_all\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[divide_into_chunks] Chromosomes: {[_chr(p) for p in af_pkls]}\")\n",
    "\n",
    "    for af_pkl in af_pkls:\n",
    "        chrom = _chr(af_pkl)\n",
    "        chrom_dir = out_root / f\"chrom_{chrom}\"; chrom_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        AF = pd.read_pickle(af_pkl)\n",
    "        AF = AF.sort_values(\"TOTAL_MAF\")\n",
    "        AF = AF.loc[AF[\"TOTAL_MAF\"] >= float(min_maf)].reset_index(drop=True)\n",
    "        if AF.empty:\n",
    "            if verbose: print(f\"[chr{chrom}] No SNPs ≥ MAF {min_maf}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        snp_ids = AF[\"ID\"].astype(str).to_numpy()\n",
    "        n_chunks = max(1, int(np.ceil(len(snp_ids)/size_chunk)))\n",
    "        chunks = np.array_split(snp_ids, n_chunks)\n",
    "        if verbose:\n",
    "            print(f\"[chr{chrom}] {len(snp_ids):,} SNPs ≥ {min_maf}; {n_chunks} chunk(s) of ~{size_chunk}\")\n",
    "\n",
    "        for i, snp_list in enumerate(chunks, start=1):\n",
    "            if len(snp_list)==0: continue\n",
    "            sel = AF[\"ID\"].isin(snp_list)\n",
    "            maf_min = float(AF.loc[sel, \"TOTAL_MAF\"].min())\n",
    "            maf_max = float(AF.loc[sel, \"TOTAL_MAF\"].max())\n",
    "            if verbose and (i==1 or i%5==0 or i==len(chunks)):\n",
    "                print(f\"[chr{chrom}] chunk {i}/{len(chunks)} size={len(snp_list)} maf=[{maf_min:.4f},{maf_max:.4f}]\")\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as td:\n",
    "                snp_file = Path(td)/\"extract.snps\"\n",
    "                snp_file.write_text(\"\\n\".join(snp_list))\n",
    "\n",
    "                pop_frames = []\n",
    "                for bfile in bfiles:\n",
    "                    cmd = [\n",
    "                        plink2_bin, \"--bfile\", bfile,\n",
    "                        \"--extract\", str(snp_file),\n",
    "                        \"--recode\", \"A\",\n",
    "                        \"--threads\", str(threads),\n",
    "                        \"--out\", \"tmp_chunk\",\n",
    "                    ]\n",
    "                    res = subprocess.run(cmd, cwd=path_input_plink_bfiles,\n",
    "                                         capture_output=True, text=True)\n",
    "                    if res.returncode != 0:\n",
    "                        raise RuntimeError(\n",
    "                            f\"[chr{chrom}][{bfile}] PLINK2 failed (code {res.returncode}).\\n\"\n",
    "                            f\"STDERR (head):\\n{res.stderr[:2000]}\"\n",
    "                        )\n",
    "\n",
    "                    raw_path = Path(path_input_plink_bfiles)/\"tmp_chunk.raw\"\n",
    "                    if not raw_path.exists():\n",
    "                        raise RuntimeError(f\"[chr{chrom}][{bfile}] Missing {raw_path}\")\n",
    "\n",
    "                    # Read .raw with stable dtypes for meta columns to avoid DtypeWarning\n",
    "                    meta_dtype = {c: \"string\" for c in PRIORITY if c != \"SEX\"}\n",
    "                    meta_dtype[\"SEX\"] = \"Int8\"   # or \"string\" if you prefer\n",
    "                    df = pd.read_csv(raw_path, sep=r\"\\s+\", low_memory=False, dtype=meta_dtype)\n",
    "\n",
    "                    cols = df.columns.tolist()\n",
    "                    meta = [c for c in PRIORITY if c in cols]\n",
    "                    gcols = [c for c in cols if c not in meta]\n",
    "\n",
    "                    # 0/1/2/NaN -> -1/0/1/<NA>\n",
    "                    df_geno = df[gcols].astype(\"Float32\") - 1.0\n",
    "                    df_geno = df_geno.astype(\"Int8\")\n",
    "                    df_final = pd.concat([df[meta], df_geno], axis=1)\n",
    "                    pop_frames.append(df_final)\n",
    "\n",
    "                    # cleanup temp PLINK outputs\n",
    "                    for ext in [\".raw\", \".log\", \".nosex\"]:\n",
    "                        p = Path(path_input_plink_bfiles)/f\"tmp_chunk{ext}\"\n",
    "                        if p.exists(): p.unlink()\n",
    "\n",
    "            combined = pd.concat(pop_frames, ignore_index=True)\n",
    "            ordered = PRIORITY + [c for c in combined.columns if c not in PRIORITY]\n",
    "            combined = combined[ordered]\n",
    "\n",
    "            out_name = f\"chunk_{i}_size_{len(snp_list)}_maf_{maf_min:.4f}-{maf_max:.4f}.parquet\"\n",
    "            combined.to_parquet(chrom_dir/out_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4efbbea-7419-4435-aa3b-face2aa06d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:23:23.178448Z",
     "iopub.status.busy": "2025-09-09T08:23:23.178100Z",
     "iopub.status.idle": "2025-09-09T08:23:23.183889Z",
     "shell.execute_reply": "2025-09-09T08:23:23.183377Z",
     "shell.execute_reply.started": "2025-09-09T08:23:23.178424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure your functions are imported or defined in this notebook/script\n",
    "# (make_AFs, concat_AFs, divide_into_chunks)\n",
    "\n",
    "path_data      = \"../../data/1000G\"           # where 1000g.bed/.bim/.fam live\n",
    "name_file      = \"1000g\"                      # prefix (no extension)\n",
    "path_plink     = \"../../\"               # directory containing plink2 binary\n",
    "path_afs       = \"../../data/1000G/afs\"       # temporary allele freq outputs\n",
    "path_afs_glob  = \"../../data/1000G/global_af\" # merged AFs\n",
    "path_chunks    = \"../../data/1000G/chunks\"    # final chunks\n",
    "\n",
    "Path(path_afs).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_afs_glob).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_chunks).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fdaefe-ac77-461a-b3a4-f9b5e8609970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:23:23.856757Z",
     "iopub.status.busy": "2025-09-09T08:23:23.856383Z",
     "iopub.status.idle": "2025-09-09T08:25:07.957650Z",
     "shell.execute_reply": "2025-09-09T08:25:07.956691Z",
     "shell.execute_reply.started": "2025-09-09T08:23:23.856733Z"
    }
   },
   "outputs": [],
   "source": [
    "make_AFs(path_data, name_file, path_plink, path_afs, threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc18ed6-a1b0-47c3-8c18-eaae68e37e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:26:47.227276Z",
     "iopub.status.busy": "2025-09-09T08:26:47.226320Z",
     "iopub.status.idle": "2025-09-09T08:27:42.777343Z",
     "shell.execute_reply": "2025-09-09T08:27:42.776677Z",
     "shell.execute_reply.started": "2025-09-09T08:26:47.227248Z"
    }
   },
   "outputs": [],
   "source": [
    "concat_AFs(path_afs, path_afs_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4212444-3fd1-4b5e-af98-19c63b38bb6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:34:47.682007Z",
     "iopub.status.busy": "2025-09-09T08:34:47.681515Z",
     "iopub.status.idle": "2025-09-09T08:36:01.748798Z",
     "shell.execute_reply": "2025-09-09T08:36:01.748133Z",
     "shell.execute_reply.started": "2025-09-09T08:34:47.681995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[divide_into_chunks] Using plink2: ../../plink2\n",
      "[divide_into_chunks] Bfiles: ['1000g']\n",
      "[divide_into_chunks] Chromosomes: ['1']\n",
      "[chr1] 948,646 SNPs ≥ 0.01; 48 chunk(s) of ~20000\n",
      "[chr1] chunk 1/48 size=19764 maf=[0.0100,0.0104]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m path_afs_glob  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/1000G/global_af\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# from concat_AFs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path_chunks    \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/1000G/chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdivide_into_chunks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_input_afs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_afs_glob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_input_plink_bfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_plink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_plink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_maf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchroms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# start with chr1 to verify\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1000g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# <— explicitly avoid 'new'\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 127\u001b[0m, in \u001b[0;36mdivide_into_chunks\u001b[0;34m(path_input_afs, path_input_plink_bfiles, path_plink, path_output, size_chunk, min_maf, threads, chroms, bfiles, verbose)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# 0/1/2/NaN -> -1/0/1/<NA>\u001b[39;00m\n\u001b[1;32m    126\u001b[0m df_geno \u001b[38;5;241m=\u001b[39m df[gcols]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m--> 127\u001b[0m df_geno \u001b[38;5;241m=\u001b[39m \u001b[43mdf_geno\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInt8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df[meta], df_geno], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    129\u001b[0m pop_frames\u001b[38;5;241m.\u001b[39mappend(df_final)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/site-packages/pandas/core/generic.py:6638\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6634\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6635\u001b[0m     \u001b[38;5;66;03m# GH 18099/22869: columnwise conversion to extension dtype\u001b[39;00m\n\u001b[1;32m   6636\u001b[0m     \u001b[38;5;66;03m# GH 24704: self.items handles duplicate column names\u001b[39;00m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 6638\u001b[0m         \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m   6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/site-packages/pandas/core/internals/blocks.py:767\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    764\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs\n\u001b[1;32m    766\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnewb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set astype for copy = [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcopy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] for dtype \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]) to different shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewb\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewb\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    772\u001b[0m     )\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newb\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/lib/python3.12/site-packages/pandas/core/internals/blocks.py:2365\u001b[0m, in \u001b[0;36mExtensionBlock.shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block_same_class(new_values, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nb\u001b[38;5;241m.\u001b[39m_maybe_downcast([nb], downcast, using_cow\u001b[38;5;241m=\u001b[39musing_cow, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfillna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): override unnecessary with 2D EAs\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2369\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues),)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_data      = \"../../data/1000G\"            # has 1000g.{bed,bim,fam}\n",
    "path_plink     = \"../../plink2\"                # binary in your tree\n",
    "path_afs_glob  = \"../../data/1000G/global_af\"  # from concat_AFs\n",
    "path_chunks    = \"../../data/1000G/chunks\"\n",
    "\n",
    "divide_into_chunks(\n",
    "    path_input_afs=path_afs_glob,\n",
    "    path_input_plink_bfiles=path_data,\n",
    "    path_plink=path_plink,\n",
    "    path_output=path_chunks,\n",
    "    size_chunk=20_000,\n",
    "    min_maf=0.01,\n",
    "    threads=8,\n",
    "    chroms=[\"1\"],          # start with chr1 to verify\n",
    "    bfiles=[\"1000g\"],      # <— explicitly avoid 'new'\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbddc72-0759-4c52-a4a4-bc1f46f4d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk = pd.read_parquet(\"../../data/1000G/chunks/chrom_1/chunk_1_size_20000_maf_0.0100-0.0135.parquet\")\n",
    "print(chunk.shape)\n",
    "print(chunk.iloc[:5, :10])   # peek\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
