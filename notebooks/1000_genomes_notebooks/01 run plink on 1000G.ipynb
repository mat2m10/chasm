{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44b427e-a340-44e9-b82f-ecbde67ff903",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb744cb-08bc-4eeb-ab37-73fb5633c9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T12:12:09.846415Z",
     "iopub.status.busy": "2025-09-10T12:12:09.846116Z",
     "iopub.status.idle": "2025-09-10T12:12:10.893140Z",
     "shell.execute_reply": "2025-09-10T12:12:10.892456Z",
     "shell.execute_reply.started": "2025-09-10T12:12:09.846394Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2726b3-f82c-4aad-abfb-695db6bc177c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T12:12:10.893868Z",
     "iopub.status.busy": "2025-09-10T12:12:10.893717Z",
     "iopub.status.idle": "2025-09-10T12:12:10.897913Z",
     "shell.execute_reply": "2025-09-10T12:12:10.897045Z",
     "shell.execute_reply.started": "2025-09-10T12:12:10.893857Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_AFs(path_data, name_file_input, path_plink, path_output, threads=4):\n",
    "    Path(path_output).mkdir(parents=True, exist_ok=True)\n",
    "    for chrom in range(1, 23):\n",
    "        name_file_output = f\"chrom_{chrom}_AFs_{name_file_input}\"\n",
    "        cmd = [\n",
    "            f\"{Path(path_plink) / 'plink2'}\",\n",
    "            \"--bfile\", name_file_input,\n",
    "            \"--chr\", str(chrom),\n",
    "            \"--freq\",\n",
    "            \"--threads\", str(threads),\n",
    "            \"--out\", str(Path(path_output) / name_file_output),\n",
    "        ]\n",
    "        # run inside path_data so relative --bfile works\n",
    "        subprocess.run(cmd, cwd=path_data, check=True, capture_output=True, text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97074e6f-70f8-4535-ba42-60d0d17b2870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T12:12:10.899105Z",
     "iopub.status.busy": "2025-09-10T12:12:10.898614Z",
     "iopub.status.idle": "2025-09-10T12:12:10.905235Z",
     "shell.execute_reply": "2025-09-10T12:12:10.904457Z",
     "shell.execute_reply.started": "2025-09-10T12:12:10.899091Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def concat_AFs(path_input, path_output):\n",
    "    Path(path_output).mkdir(parents=True, exist_ok=True)\n",
    "    af_files = [f for f in os.listdir(path_input) if f.endswith(\".afreq\")]\n",
    "    chroms = sorted({f.split('_')[1] for f in af_files})  # 'chrom_1', etc.\n",
    "    pops = sorted({f.split(\"_AFs_\")[1].split(\".\")[0] for f in af_files})\n",
    "\n",
    "    for chrom in chroms:\n",
    "        dfs = []\n",
    "        for pop in pops:\n",
    "            p = Path(path_input) / f\"chrom_{chrom}_AFs_{pop}.afreq\"\n",
    "            df = pd.read_csv(p, sep=r\"\\s+\")\n",
    "            # ALT_FREQS is AF for ALT; fold to MAF only at the end after weighting\n",
    "            df = df.rename(columns={\"ALT_FREQS\": f\"ALT_FREQS_{pop}\", \"OBS_CT\": f\"OBS_CT_{pop}\"})\n",
    "            dfs.append(df)\n",
    "\n",
    "        base = dfs[0]\n",
    "        for d in dfs[1:]:\n",
    "            base = base.merge(d, on=[\"#CHROM\",\"ID\",\"REF\",\"ALT\",\"PROVISIONAL_REF?\"], how=\"inner\")\n",
    "\n",
    "        # Weighted global ALT freq across populations\n",
    "        total_alt = 0.0\n",
    "        total_obs = 0.0\n",
    "        for pop in pops:\n",
    "            base[f\"ALT_COUNT_{pop}\"] = base[f\"ALT_FREQS_{pop}\"] * base[f\"OBS_CT_{pop}\"]\n",
    "            total_alt += base[f\"ALT_COUNT_{pop}\"]\n",
    "            total_obs += base[f\"OBS_CT_{pop}\"]\n",
    "        base[\"TOTAL_ALT_FREQ\"] = (total_alt / total_obs).astype(\"float32\")\n",
    "\n",
    "        # Convert to **MAF** in [0, 0.5]\n",
    "        base[\"TOTAL_MAF\"] = np.minimum(base[\"TOTAL_ALT_FREQ\"], 1.0 - base[\"TOTAL_ALT_FREQ\"]).astype(\"float32\")\n",
    "\n",
    "        base.to_pickle(Path(path_output) / f\"global_AF_{chrom}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea6fc53-5bc1-4f47-a1d8-fb8de25181f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T12:12:11.551299Z",
     "iopub.status.busy": "2025-09-10T12:12:11.550969Z",
     "iopub.status.idle": "2025-09-10T12:12:11.567057Z",
     "shell.execute_reply": "2025-09-10T12:12:11.565950Z",
     "shell.execute_reply.started": "2025-09-10T12:12:11.551278Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "PRIORITY = [\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\",\"PHENOTYPE\"]\n",
    "\n",
    "def _resolve_plink2(path_plink: str) -> str:\n",
    "    p = Path(path_plink)\n",
    "    if p.is_file() and os.access(p, os.X_OK):\n",
    "        return str(p)\n",
    "    cand = p / \"plink2\"\n",
    "    if cand.is_file() and os.access(cand, os.X_OK):\n",
    "        return str(cand)\n",
    "    which = shutil.which(\"plink2\")\n",
    "    if which: \n",
    "        return which\n",
    "    raise FileNotFoundError(f\"plink2 not found at '{path_plink}' and not in PATH\")\n",
    "\n",
    "def _find_bfiles(path_dir: str):\n",
    "    d = Path(path_dir)\n",
    "    fams = {p.stem for p in d.glob(\"*.fam\")}\n",
    "    trios = [pref for pref in sorted(fams)\n",
    "             if (d/f\"{pref}.bed\").exists() and (d/f\"{pref}.bim\").exists()]\n",
    "    return trios\n",
    "\n",
    "def divide_into_chunks(path_input_afs,\n",
    "                       path_input_plink_bfiles,\n",
    "                       path_plink,\n",
    "                       path_output,\n",
    "                       size_chunk=20_000,\n",
    "                       min_maf=0.01,\n",
    "                       threads=4,\n",
    "                       chroms=None,\n",
    "                       bfiles=None,\n",
    "                       verbose=True):\n",
    "    try:\n",
    "        plink2_bin = _resolve_plink2(path_plink)\n",
    "        out_root = Path(path_output); out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        auto_bfiles = _find_bfiles(path_input_plink_bfiles)\n",
    "        if bfiles is None:\n",
    "            bfiles = auto_bfiles\n",
    "        else:\n",
    "            bfiles = [b for b in bfiles if b in auto_bfiles]\n",
    "\n",
    "        if not bfiles:\n",
    "            raise RuntimeError(f\"No valid PLINK bfiles found. Present trios: {auto_bfiles}\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[divide_into_chunks] Using plink2: {plink2_bin}\")\n",
    "            print(f\"[divide_into_chunks] Bfiles: {bfiles}\")\n",
    "\n",
    "        # be explicit about the pattern you produced earlier\n",
    "        af_pkls_all = sorted(Path(path_input_afs).glob(\"global_AF_chrom_*.pkl\"))\n",
    "        if not af_pkls_all:\n",
    "            # fall back to the broader pattern, but log it\n",
    "            af_pkls_all = sorted(Path(path_input_afs).glob(\"global_AF_*.pkl\"))\n",
    "        if not af_pkls_all:\n",
    "            raise RuntimeError(f\"No AF files in {path_input_afs}\")\n",
    "\n",
    "        def _chr(p): return p.stem.split(\"_\")[-1]\n",
    "        if chroms is not None:\n",
    "            keep = {str(c) for c in chroms}\n",
    "            af_pkls = [p for p in af_pkls_all if _chr(p) in keep]\n",
    "        else:\n",
    "            af_pkls = af_pkls_all\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[divide_into_chunks] Found {len(af_pkls)} AF file(s). First few:\")\n",
    "            for q in af_pkls[:5]:\n",
    "                print(\"  -\", q.name)\n",
    "            print(f\"[divide_into_chunks] Chromosomes to process: {[_chr(p) for p in af_pkls]}\")\n",
    "\n",
    "        for af_pkl in af_pkls:\n",
    "            chrom = _chr(af_pkl)\n",
    "            chrom_dir = out_root / f\"chrom_{chrom}\"; chrom_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            AF = pd.read_pickle(af_pkl)\n",
    "            if \"TOTAL_MAF\" not in AF.columns:\n",
    "                raise ValueError(f\"{af_pkl} missing TOTAL_MAF. Did you run concat_AFs() from the updated code?\")\n",
    "            AF = AF.sort_values(\"TOTAL_MAF\")\n",
    "            AF = AF.loc[AF[\"TOTAL_MAF\"] >= float(min_maf)].reset_index(drop=True)\n",
    "            if AF.empty:\n",
    "                if verbose: print(f\"[chr{chrom}] No SNPs ≥ MAF {min_maf}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            snp_ids = AF[\"ID\"].astype(str).to_numpy()\n",
    "            n_chunks = max(1, int(np.ceil(len(snp_ids)/size_chunk)))\n",
    "            chunks = np.array_split(snp_ids, n_chunks)\n",
    "            if verbose:\n",
    "                print(f\"[chr{chrom}] {len(snp_ids):,} SNPs ≥ {min_maf}; {n_chunks} chunk(s) of ~{size_chunk}\")\n",
    "\n",
    "            for i, snp_list in enumerate(chunks, start=1):\n",
    "                if len(snp_list)==0: \n",
    "                    continue\n",
    "                sel = AF[\"ID\"].isin(snp_list)\n",
    "                maf_min = float(AF.loc[sel, \"TOTAL_MAF\"].min())\n",
    "                maf_max = float(AF.loc[sel, \"TOTAL_MAF\"].max())\n",
    "                if verbose and (i==1 or i%5==0 or i==len(chunks)):\n",
    "                    print(f\"[chr{chrom}] chunk {i}/{len(chunks)} size={len(snp_list)} maf=[{maf_min:.4f},{maf_max:.4f}]\")\n",
    "\n",
    "                with tempfile.TemporaryDirectory() as td:\n",
    "                    snp_file = Path(td)/\"extract.snps\"\n",
    "                    snp_file.write_text(\"\\n\".join(snp_list))\n",
    "\n",
    "                    pop_frames = []\n",
    "                    for bfile in bfiles:\n",
    "                        cmd = [\n",
    "                            plink2_bin, \"--bfile\", bfile,\n",
    "                            \"--extract\", str(snp_file),\n",
    "                            \"--recode\", \"A\",\n",
    "                            \"--threads\", str(threads),\n",
    "                            \"--out\", \"tmp_chunk\",\n",
    "                        ]\n",
    "                        # make errors visible immediately\n",
    "                        res = subprocess.run(cmd, cwd=path_input_plink_bfiles,\n",
    "                                             capture_output=True, text=True, check=False)\n",
    "                        if res.returncode != 0:\n",
    "                            print(\"---- PLINK2 STDERR ----\")\n",
    "                            print(res.stderr[:4000])\n",
    "                            print(\"------------------------\")\n",
    "                            raise RuntimeError(\n",
    "                                f\"[chr{chrom}][{bfile}] PLINK2 failed (code {res.returncode}).\"\n",
    "                            )\n",
    "\n",
    "                        raw_path = Path(path_input_plink_bfiles)/\"tmp_chunk.raw\"\n",
    "                        if not raw_path.exists():\n",
    "                            raise RuntimeError(f\"[chr{chrom}][{bfile}] Missing {raw_path}\")\n",
    "\n",
    "                        meta_dtype = {c: \"string\" for c in PRIORITY if c != \"SEX\"}\n",
    "                        meta_dtype[\"SEX\"] = \"Int8\"\n",
    "                        df = pd.read_csv(raw_path, sep=r\"\\s+\", low_memory=False, dtype=meta_dtype)\n",
    "\n",
    "                        cols = df.columns.tolist()\n",
    "                        meta = [c for c in PRIORITY if c in cols]\n",
    "                        gcols = [c for c in cols if c not in meta]\n",
    "\n",
    "                        df_geno = df[gcols].astype(\"Float32\") - 1.0\n",
    "                        df_geno = df_geno.astype(\"Int8\")\n",
    "                        df_final = pd.concat([df[meta], df_geno], axis=1)\n",
    "                        pop_frames.append(df_final)\n",
    "\n",
    "                        for ext in [\".raw\", \".log\", \".nosex\"]:\n",
    "                            p = Path(path_input_plink_bfiles)/f\"tmp_chunk{ext}\"\n",
    "                            if p.exists(): p.unlink()\n",
    "\n",
    "                combined = pd.concat(pop_frames, ignore_index=True)\n",
    "                ordered = PRIORITY + [c for c in combined.columns if c not in PRIORITY]\n",
    "                combined = combined[ordered]\n",
    "\n",
    "                out_name = f\"chunk_{i}_size_{len(snp_list)}_maf_{maf_min:.4f}-{maf_max:.4f}.pkl\"\n",
    "                combined.to_pickle(chrom_dir/out_name)  # <-- no index= kw for to_pickle\n",
    "\n",
    "        if verbose:\n",
    "            print(\"[divide_into_chunks] Done.\")\n",
    "    except Exception as e:\n",
    "        # print a readable traceback so you see the *actual* cause\n",
    "        print(\"ERROR in divide_into_chunks:\\n\")\n",
    "        traceback.print_exc()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4efbbea-7419-4435-aa3b-face2aa06d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T12:12:12.797128Z",
     "iopub.status.busy": "2025-09-10T12:12:12.796810Z",
     "iopub.status.idle": "2025-09-10T12:12:12.805414Z",
     "shell.execute_reply": "2025-09-10T12:12:12.804276Z",
     "shell.execute_reply.started": "2025-09-10T12:12:12.797106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure your functions are imported or defined in this notebook/script\n",
    "# (make_AFs, concat_AFs, divide_into_chunks)\n",
    "\n",
    "path_data      = \"../../data/1000G\"           # where 1000g.bed/.bim/.fam live\n",
    "name_file      = \"1000g\"                      # prefix (no extension)\n",
    "path_plink     = \"../../\"               # directory containing plink2 binary\n",
    "path_afs       = \"../../data/1000G/afs\"       # temporary allele freq outputs\n",
    "path_afs_glob  = \"../../data/1000G/global_af\" # merged AFs\n",
    "path_chunks    = \"../../data/1000G/chunks\"    # final chunks\n",
    "\n",
    "Path(path_afs).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_afs_glob).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_chunks).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fdaefe-ac77-461a-b3a4-f9b5e8609970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:23:23.856757Z",
     "iopub.status.busy": "2025-09-09T08:23:23.856383Z",
     "iopub.status.idle": "2025-09-09T08:25:07.957650Z",
     "shell.execute_reply": "2025-09-09T08:25:07.956691Z",
     "shell.execute_reply.started": "2025-09-09T08:23:23.856733Z"
    }
   },
   "outputs": [],
   "source": [
    "make_AFs(path_data, name_file, path_plink, path_afs, threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc18ed6-a1b0-47c3-8c18-eaae68e37e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:26:47.227276Z",
     "iopub.status.busy": "2025-09-09T08:26:47.226320Z",
     "iopub.status.idle": "2025-09-09T08:27:42.777343Z",
     "shell.execute_reply": "2025-09-09T08:27:42.776677Z",
     "shell.execute_reply.started": "2025-09-09T08:26:47.227248Z"
    }
   },
   "outputs": [],
   "source": [
    "concat_AFs(path_afs, path_afs_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f77acd0-3ace-4f62-8c1c-e939e381daa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T12:12:17.982060Z",
     "iopub.status.busy": "2025-09-10T12:12:17.981747Z",
     "iopub.status.idle": "2025-09-10T12:22:28.614271Z",
     "shell.execute_reply": "2025-09-10T12:22:28.613540Z",
     "shell.execute_reply.started": "2025-09-10T12:12:17.982039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[divide_into_chunks] Using plink2: ../../plink2\n",
      "[divide_into_chunks] Bfiles: ['1000g']\n",
      "[divide_into_chunks] Found 1 AF file(s). First few:\n",
      "  - global_AF_20.pkl\n",
      "[divide_into_chunks] Chromosomes to process: ['20']\n",
      "[chr20] 150,215 SNPs ≥ 0.05; 76 chunk(s) of ~2000\n",
      "[chr20] chunk 1/76 size=1977 maf=[0.0501,0.0519]\n",
      "[chr20] chunk 5/76 size=1977 maf=[0.0589,0.0615]\n",
      "[chr20] chunk 10/76 size=1977 maf=[0.0725,0.0755]\n",
      "[chr20] chunk 15/76 size=1977 maf=[0.0883,0.0917]\n",
      "[chr20] chunk 20/76 size=1977 maf=[0.1073,0.1113]\n",
      "[chr20] chunk 25/76 size=1977 maf=[0.1290,0.1336]\n",
      "[chr20] chunk 30/76 size=1977 maf=[0.1540,0.1592]\n",
      "[chr20] chunk 35/76 size=1977 maf=[0.1816,0.1874]\n",
      "[chr20] chunk 40/76 size=1976 maf=[0.2109,0.2173]\n",
      "[chr20] chunk 45/76 size=1976 maf=[0.2429,0.2499]\n",
      "[chr20] chunk 50/76 size=1976 maf=[0.2791,0.2871]\n",
      "[chr20] chunk 55/76 size=1976 maf=[0.3178,0.3258]\n",
      "[chr20] chunk 60/76 size=1976 maf=[0.3578,0.3660]\n",
      "[chr20] chunk 65/76 size=1976 maf=[0.3997,0.4087]\n",
      "[chr20] chunk 70/76 size=1976 maf=[0.4427,0.4513]\n",
      "[chr20] chunk 75/76 size=1976 maf=[0.4840,0.4916]\n",
      "[chr20] chunk 76/76 size=1976 maf=[0.4916,0.5000]\n",
      "[divide_into_chunks] Done.\n"
     ]
    }
   ],
   "source": [
    "for chrom in list(range(23))[-4:-3]:\n",
    "    chrom += 1\n",
    "    divide_into_chunks(\n",
    "        path_input_afs=path_afs_glob,\n",
    "        path_input_plink_bfiles=path_data,\n",
    "        path_plink=path_plink,\n",
    "        path_output=path_chunks,\n",
    "        size_chunk=2000,\n",
    "        min_maf=0.05,\n",
    "        threads=8,\n",
    "        chroms=[f\"{chrom}\"],          # start with chr1 to verify\n",
    "        bfiles=[\"1000g\"],      # <— explicitly avoid 'new'\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbddc72-0759-4c52-a4a4-bc1f46f4d5e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:54:07.110074Z",
     "iopub.status.busy": "2025-09-09T08:54:07.109288Z",
     "iopub.status.idle": "2025-09-09T08:54:07.118975Z",
     "shell.execute_reply": "2025-09-09T08:54:07.118408Z",
     "shell.execute_reply.started": "2025-09-09T08:54:07.110041Z"
    }
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#chunk = pd.read_pickle(\"../../data/1000G/chunks/chrom_1/chunk_1_size_200_maf_0.0100-0.0100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab5650-18dc-4e45-ac7e-a7be01bbeafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
